# AnÃ¡lise de Modelos de RegressÃ£o para PrevisÃ£o de PrecipitaÃ§Ã£o ğŸŒ§ï¸
## Contexto ğŸŒ

Este relatÃ³rio conduz uma anÃ¡lise detalhada dos modelos de regressÃ£o aplicados Ã  previsÃ£o da quantidade total de precipitaÃ§Ã£o em Campo Grande. Exploraremos mÃ©tricas, visualizaÃ§Ãµes e comparaÃ§Ãµes entre modelos, proporcionando uma compreensÃ£o abrangente das tÃ©cnicas empregadas. 

## MÃ©tricas de AvaliaÃ§Ã£o ğŸ“

### Mean Absolute Error (MAE) ğŸ˜®
- **InterpretaÃ§Ã£o:** Uma mÃ©dia absoluta dos erros entre as previsÃµes e os valores reais. Quanto menor, melhor.
- **Exemplo de Uso:**
  ```python
  from sklearn.metrics import mean_absolute_error
  mae = mean_absolute_error(Y_test, previsoes)
  ```

### Mean Squared Error (MSE) ğŸ“‰
- **InterpretaÃ§Ã£o:** Uma mÃ©dia dos quadrados dos erros entre as previsÃµes e os valores reais. Quanto menor, melhor.
- **Exemplo de Uso:**
  ```python
  from sklearn.metrics import mean_squared_error
  mse = mean_squared_error(Y_test, previsoes)
  ```

### R-squared (RÂ²) ğŸ“ˆ
- **InterpretaÃ§Ã£o:** Coeficiente de determinaÃ§Ã£o. Varia de 0 a 1, sendo 1 o melhor resultado. Indica a proporÃ§Ã£o da variÃ¢ncia na variÃ¡vel dependente que Ã© previsÃ­vel a partir das variÃ¡veis independentes.
- **Exemplo de Uso:**
  ```python
  from sklearn.metrics import r2_score
  r2 = r2_score(Y_test, previsoes)
  ```
  Esses resultados sugerem que o modelo estÃ¡ se ajustando muito bem aos dados de treinamento. No entanto, Ã© importante ter cuidado com a possibilidade de overfitting, especialmente se o modelo estiver muito complexo e ajustado demais aos dados de treinamento especÃ­ficos.

  AlÃ©m disso, ao considerar a qualidade do modelo, tambÃ©m Ã© crucial avaliÃ¡-lo em um conjunto de teste independente para garantir que ele generalize bem para dados nÃ£o vistos. Certifique-se de usar um conjunto de teste separado para avaliaÃ§Ã£o adequada do desempenho do modelo.


## VisualizaÃ§Ã£o 3D AvanÃ§ada ğŸŒğŸ“Š

A visualizaÃ§Ã£o 3D interativa fornece insights sobre a distribuiÃ§Ã£o espacial dos pontos de teste. Utilizamos a biblioteca Plotly para criar um ambiente exploratÃ³rio imersivo.

```python
import plotly.graph_objects as go

# CriaÃ§Ã£o do grÃ¡fico 3D
fig = go.Figure()

# AdiÃ§Ã£o dos pontos reais e previstos
fig.add_trace(go.Scatter3d(x=X_test.iloc[:, 0], y=X_test.iloc[:, 1], z=Y_test, mode='markers', marker=dict(color='black', size=5), name='Real'))
fig.add_trace(go.Scatter3d(x=X_test.iloc[:, 0], y=X_test.iloc[:, 1], z=previsoes, mode='markers', marker=dict(color='red', size=5), name='Previsto'))

# ConfiguraÃ§Ã£o do layout
fig.update_layout(scene=dict(xaxis_title='Primeira VariÃ¡vel Independente', yaxis_title='Segunda VariÃ¡vel Independente', zaxis_title='PRECIP. TOTAL (mm)'),
                  scene_camera=dict(up=dict(x=0, y=0, z=1), center=dict(x=0, y=0, z=0), eye=dict(x=1.25, y=1.25, z=1.25)))

# ExibiÃ§Ã£o do grÃ¡fico
fig.show()
```
- **GrÃ¡fico:**

 ![GrÃ¡fico de DispersÃ£o - RegressÃ£o Linear](report/Linear%20Regression3D.png)

## Modelos de RegressÃ£o AvanÃ§ada ğŸ¤–ğŸ’¡

### RegressÃ£o Linear
- **DescriÃ§Ã£o:** Modelo linear simples que assume uma relaÃ§Ã£o linear entre variÃ¡veis independentes e dependentes.
- **Exemplo de Uso:**
  ```python
  from sklearn.linear_model import LinearRegression
  model = LinearRegression()
  model.fit(X_train, Y_train)
  previsoes = model.predict(X_test)
  ```
- **AvaliaÃ§Ã£o:**
    - MAE: 63.93
    - MSE: 1567541.57
    - R-squared: 0.65
- **GrÃ¡fico:**

  ![GrÃ¡fico de DispersÃ£o - RegressÃ£o Linear](report/Linear%20Regression.png)

### Ãrvore de DecisÃ£o
- **DescriÃ§Ã£o:** Modelo baseado em estruturas de Ã¡rvore que divide o conjunto de dados em subconjuntos.
- **Exemplo de Uso:**
  ```python
  from sklearn.tree import DecisionTreeRegressor
  model = DecisionTreeRegressor()
  model.fit(X_train, Y_train)
  previsoes = model.predict(X_test)
  ```
- **AvaliaÃ§Ã£o:**
    - MAE: 114.24
    - MSE: 258569.75
    - R-squared: 0.94
- **GrÃ¡fico:**

  ![GrÃ¡fico de DispersÃ£o - Ãrvore de DecisÃ£o](report/Decision%20Tree.png)

### Random Forest
- **DescriÃ§Ã£o:** Ensemble de Ã¡rvores de decisÃ£o, reduzindo overfitting e melhorando a precisÃ£o.
- **Exemplo de Uso:**
  ```python
  from sklearn.ensemble import RandomForestRegressor
  model = RandomForestRegressor()
  model.fit(X_train, Y_train)
  previsoes = model.predict(X_test)
  ```
- **AvaliaÃ§Ã£o:**
    - MAE: 114.19
    - MSE: 137050.10
    - R-squared: 0.97
- **GrÃ¡fico:**

  ![GrÃ¡fico de DispersÃ£o - Random Forest](report/Random%20Forest.png)

### Gradient Boosting
- **DescriÃ§Ã£o:** Ensemble de Ã¡rvores treinadas sequencialmente, corrigindo erros dos modelos anteriores.
- **Exemplo de Uso:**
  ```python
  from sklearn.ensemble import GradientBoostingRegressor
  model = GradientBoostingRegressor()
  model.fit(X_train, Y_train)
  previsoes = model.predict(X_test)
  ```
- **AvaliaÃ§Ã£o:**
    - MAE: 48.82
    - MSE: 51558.87
    - R-squared: 0.99
- **GrÃ¡fico:**

  ![GrÃ¡fico de DispersÃ£o - Gradient Boosting](report/Gradient%20Boosting.png)

# DivisÃ£o do Conjunto de Dados para Treinamento e Teste ğŸ“‚
```python
from sklearn.model_selection import train_test_split

# Dividindo o conjunto de dados em conjuntos de treinamento e teste
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=1)
```

**Nota Importante:**
Os resultados apresentados podem variar devido ao parÃ¢metro `test_size` nesta divisÃ£o de dados. O valor de `test_size` representa a proporÃ§Ã£o dos dados que serÃ£o utilizados como conjunto de teste, enquanto o restante Ã© utilizado como conjunto de treinamento. ğŸ”„

### ExplicaÃ§Ã£o:

- **`X` e `Y`:** Representam as caracterÃ­sticas (features) e as variÃ¡veis de resposta (target), respectivamente, do conjunto de dados.

- **`test_size=0.1`:** Este parÃ¢metro define a proporÃ§Ã£o do conjunto de dados que serÃ¡ utilizado como conjunto de teste. Neste caso, 10% dos dados serÃ£o reservados para teste, e 90% serÃ£o utilizados para treinamento. ğŸ”

- **`random_state=1`:** Este parÃ¢metro Ã© opcional, mas Ã© usado para garantir reprodutibilidade. Ao definir um valor fixo para `random_state`, a divisÃ£o serÃ¡ sempre a mesma se o cÃ³digo for executado vÃ¡rias vezes com o mesmo conjunto de dados. Isso Ã© Ãºtil para resultados consistentes e para evitar variaÃ§Ãµes nos resultados durante o desenvolvimento e teste do modelo. ğŸš€

### Aviso:

Ã‰ importante observar que a escolha do `test_size` influenciarÃ¡ diretamente na avaliaÃ§Ã£o do desempenho do modelo. Um tamanho de teste muito pequeno pode levar a uma estimativa instÃ¡vel do desempenho, enquanto um tamanho muito grande pode resultar em uma diminuiÃ§Ã£o na quantidade de dados disponÃ­veis para treinamento.

Ao ajustar o valor de `test_size`, Ã© recomendÃ¡vel considerar a quantidade total de dados disponÃ­veis e o trade-off entre a precisÃ£o da avaliaÃ§Ã£o do modelo e a quantidade de dados usada para treinamento. ğŸ§ğŸ“Š

## Escolha do Modelo e ConsideraÃ§Ãµes ğŸ¤”ğŸ“ˆ

### 1. RegressÃ£o Linear ğŸ¤–:

**DescriÃ§Ã£o:**
A RegressÃ£o Linear Ã© um modelo simples que pressupÃµe uma relaÃ§Ã£o linear entre as variÃ¡veis independentes e dependentes. Em outras palavras, ele tenta encontrar a melhor linha reta que se ajusta aos dados.

**Vantagens:**
- ğŸ“Š **FÃ¡cil interpretaÃ§Ã£o:** Ideal quando a compreensÃ£o direta da relaÃ§Ã£o entre variÃ¡veis Ã© crucial.
- ğŸ’» **Computacionalmente eficiente:** RÃ¡pido e eficaz em conjuntos de dados menores.
- ğŸ”„ **Ãštil para relaÃ§Ãµes lineares:** Funciona bem quando a relaÃ§Ã£o entre variÃ¡veis Ã© aproximadamente linear.

**Desvantagens:**
- ğŸ“ˆ **Limitado a relaÃ§Ãµes lineares:** Pode nÃ£o lidar bem com dados que tÃªm relaÃ§Ãµes nÃ£o-lineares.
- ğŸ“‰ **Sensibilidade a outliers:** Resultados podem ser afetados por valores extremos.

### 2. Ãrvore de DecisÃ£o ğŸŒ³:

**DescriÃ§Ã£o:**
A Ãrvore de DecisÃ£o Ã© um modelo baseado em estruturas de Ã¡rvore que divide o conjunto de dados em subconjuntos, tomando decisÃµes em cada nÃ³. Cada divisÃ£o Ã© baseada em uma condiÃ§Ã£o que maximiza a pureza dos subconjuntos resultantes.

**Vantagens:**
- ğŸŒ³ **Lida bem com relaÃ§Ãµes nÃ£o-lineares:** Capaz de capturar padrÃµes complexos nos dados.
- ğŸš« **NÃ£o requer normalizaÃ§Ã£o de variÃ¡veis:** Robusto a diferentes escalas de variÃ¡veis.
- ğŸ“Š **FÃ¡cil interpretaÃ§Ã£o:** Possibilita visualizaÃ§Ã£o clara do processo de decisÃ£o.

**Desvantagens:**
- ğŸš€ **TendÃªncia a overfitting:** Especialmente em Ã¡rvores profundas, pode se ajustar demais aos dados de treinamento.
- ğŸ“ˆ **Sensibilidade a pequenas variaÃ§Ãµes nos dados:** Pequenas mudanÃ§as nos dados podem levar a grandes alteraÃ§Ãµes na Ã¡rvore.

### 3. Random Forest ğŸŒ²:

**DescriÃ§Ã£o:**
Random Forest Ã© um ensemble de Ã¡rvores de decisÃ£o, onde vÃ¡rias Ã¡rvores sÃ£o treinadas e a previsÃ£o final Ã© a mÃ©dia (regressÃ£o) ou a votaÃ§Ã£o (classificaÃ§Ã£o) das previsÃµes individuais.

**Vantagens:**
- ğŸŒ² **Reduz overfitting:** Ao combinar vÃ¡rias Ã¡rvores, ajuda a generalizar melhor para novos dados.
- ğŸŒ **Lida bem com relaÃ§Ãµes nÃ£o-lineares:** Capaz de capturar padrÃµes complexos e interaÃ§Ãµes.
- ğŸ›¡ï¸ **Robusto a outliers:** Menos suscetÃ­vel a ser influenciado por valores extremos.

**Desvantagens:**
- ğŸ” **Menos interpretÃ¡vel:** Dificuldade em entender o processo de decisÃ£o quando comparado a uma Ãºnica Ã¡rvore.
  
### 4. Gradient Boosting ğŸ“ˆ:

**DescriÃ§Ã£o:**
Gradient Boosting Ã© um ensemble de Ã¡rvores que sÃ£o treinadas sequencialmente, corrigindo os erros dos modelos anteriores.

**Vantagens:**
- ğŸ“ˆ **Alta precisÃ£o preditiva:** Pode fornecer resultados altamente precisos.
- ğŸŒ **Lida bem com relaÃ§Ãµes nÃ£o-lineares:** Capaz de capturar padrÃµes complexos e interaÃ§Ãµes.
- ğŸ›¡ï¸ **Robusto a outliers:** Menos sensÃ­vel a valores extremos.

**Desvantagens:**
- ğŸšï¸ **Sensibilidade a hiperparÃ¢metros:** Requer ajuste cuidadoso dos parÃ¢metros.
- ğŸ•°ï¸ **Tempo de treinamento mais longo:** Pode levar mais tempo em comparaÃ§Ã£o com mÃ©todos mais simples.

### Escolha do Modelo:

- **RegressÃ£o Linear:** Use quando a relaÃ§Ã£o Ã© linear e interpretabilidade Ã© crucial.
  
- **Ãrvore de DecisÃ£o:** Use quando as relaÃ§Ãµes sÃ£o nÃ£o-lineares e interpretaÃ§Ã£o fÃ¡cil Ã© desejada.

- **Random Forest:** Use quando precisar de alta precisÃ£o preditiva e interpretabilidade nÃ£o Ã© crÃ­tica.

- **Gradient Boosting:** Use quando a precisÃ£o Ã© crucial, e vocÃª estÃ¡ disposto a ajustar hiperparÃ¢metros.

A escolha entre modelos depende da natureza do problema, da interpretabilidade desejada e da necessidade de precisÃ£o. Experimentar vÃ¡rios modelos e ajustar hiperparÃ¢metros Ã© recomendado para encontrar a melhor soluÃ§Ã£o.

## Tamanho do Conjunto de Teste ğŸ§ğŸ“‰

Ao diminuir o conjunto de teste, hÃ¡ variaÃ§Ã£o estatÃ­stica aumentada, menor representatividade e maior risco de overfitting. Conjuntos de teste maiores proporcionam avaliaÃ§Ãµes mais estÃ¡veis e confiÃ¡veis do desempenho do modelo.

Este relatÃ³rio fornece uma visÃ£o abrangente da modelagem realizada, incorporando conceitos avanÃ§ados, tÃ©cnicas de visualizaÃ§Ã£o e anÃ¡lises detalhadas para impulsionar o entendimento e aprimoramento dos modelos. ğŸš€ğŸ”
